{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep your finger on the PULSE of super resolution\n",
    "#### _PULSE implementation explained_\n",
    "\n",
    "[PULSE paper](https://arxiv.org/abs/2003.03808) | [Medium.com article](TODO)\n",
    "\n",
    "This notebook walks you though the core PULSE implementation step by step.\n",
    "Clone this notebook to CUDA environment and give yourself 15 min to read and run every cell of this notebook.\n",
    "Generating a super-resolution image takes as few as few seconds.\n",
    "\n",
    "Let's get started!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from stylegan import G_synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need an image of a face to work on.\n",
    "Ideally, the image has to have 3 channels and has to be square.\n",
    "The face should be cented.\n",
    "You can upload your own image or use a picture of mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"img/przemek32.png\"\n",
    "img_lr = transforms.ToTensor()(Image.open(img_path).convert('RGB')).unsqueeze(0).cuda()\n",
    "img_lr_res = img_lr[0].size()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be working on the following image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(transforms.ToPILImage()(img_lr[0].cpu())))\n",
    "plt.title(\"Low resolution image ({} x {})\".format(img_lr_res[0], img_lr_res[0]))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator - StyleGAN\n",
    "\n",
    "As in the original paper, we will be using pretrained *StyleGAN* downloaded from the Internet. First, make sure you have `synthesis.pt` and `gaussian_fit.pt` in `models` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/ img/\n",
    "!wget -nc -O \"models/synthesis.pt\" https://drive.google.com/uc?id=1TCViX1YpQyRsklTVYEJwdbmK91vklCo8\n",
    "!wget -nc -O \"models/gaussian_fit.pt\" https://drive.google.com/uc?id=14R6iHGf5iuVx3DMNsACAl7eBr7Vdpd0k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = G_synthesis().cuda()\n",
    "generator.load_state_dict(torch.load(\"models/synthesis.pt\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StyleGAN's generator conists of three parts:\n",
    " -  Mapping: $R^{512} \\rightarrow R^{512}$\n",
    " -  Tiling function: $R^{512} \\rightarrow R^{18\\times 512}$\n",
    "     - This functions tiles (repeats) given tensor 18 times.\n",
    " -  Synthesis: $R^{18\\times 512} \\times \\textit{noise} \\rightarrow R^{1024\\times 1024}$.\n",
    " \n",
    "To generate an image, initialize latent vector $z$ randomly and feed it through the above.\n",
    "However, we can skip the mapping provided we fit $z$ to the mapping latent distibution.\n",
    "Again, will be using already pertrained data.\n",
    "`gaussian_fit` is a dictionary containing mean and standard deviation of the mapping latent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_fit = torch.load(\"models/gaussian_fit.pt\");\n",
    "gaussian_fit.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit $z$, we multiply it by the mean, add the standard deviation and feed through Leaky ReLU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrelu = torch.nn.LeakyReLU(negative_slope=0.025);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we need to freeze StyleGAN parameters.\n",
    "What PULSE optimizes is the latent vector $z$ itself and the StyleGAN is used to generate images solely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in generator.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StyleGAN: Noise\n",
    "Besides a latent vector, StyleGAN's synthesis takes one more parameter: noise.\n",
    "The noise contols artistic features of generated image.\n",
    "There are 18 noise vectors, each for one interal layer of the synthesis.\n",
    "\n",
    "In PULSE, they proposed following noise types:\n",
    "\n",
    " - first 5 layers get a trainable noise\n",
    " - next layers get a fixed, non-trainable noise\n",
    " - the last, 18-th layer gets no noise (fixed zero noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_trainable = [torch.randn((1, 1, 2**(i//2+2), 2**(i//2+2)), \n",
    "                   dtype=torch.float, device='cuda', requires_grad=True) \n",
    "                   for i in range(5)]\n",
    "\n",
    "noise_fixed = [torch.randn((1, 1, 2**(i//2+2), 2**(i//2+2)), \n",
    "               dtype=torch.float, device='cuda', requires_grad=False) \n",
    "               for i in range(5, 17)]\n",
    "\n",
    "noise_zero = [torch.zeros((1, 1, 2**(17//2+2), 2**(17//2+2)), \n",
    "              dtype=torch.float, device='cuda', requires_grad=False)]\n",
    "\n",
    "noise = noise_trainable + noise_fixed + noise_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Latent Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, to draw **uniformly** from the hypersphere, first we gotta draw a latent vector from normal distibution, and then normalize it by the sphere radius\n",
    "([Method 19](http://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/)).\n",
    "The latent tensor contains one, $512$-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = torch.randn((1, 1, 512), dtype=torch.float, device='cuda', requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latent vector has to lie on the hypersphere of radius $r =\\sqrt{511}$.\n",
    "To enforce that, simply divide the vector by the radius length.\n",
    "Why is the radius $\\sqrt{511}$? Because it's where mass of the gaussian lies.\n",
    "Check the paper, Section 6.2 for detailed explanation.\n",
    "\n",
    "However, we won't divide the latent by $\\sqrt{511}$.\n",
    "Instead, we will exploit the following fact: expected length of a random $512$-dim vector is $\\approx\\sqrt{511}$.\n",
    "We will take $r$ as the length of the initailly randomly drawn vector.\n",
    "Thus we won't be on the sphere _precisely_, but _somewhere close_ to it.\n",
    "This way, it is expected to obtain a little bit more _diversed_ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 0\n",
    "with torch.no_grad():\n",
    "    radius = latent.norm(dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can verify that the randomly generated vector _indeed is_ close the hypersphere of radius $\\sqrt{511}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"| sqrt(511) - |z| | = {:.4}\".format(np.abs(np.sqrt(511) - radius.cpu().item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "We will use Adam optimizer with learning rate = 0.4.\n",
    "Again, what we optimize in PULSE is just the latent vector and the trainable noise for the StyleGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([latent] + noise_trainable, lr=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that after the optimzer step the latent vector might not lie on the sphere anymore.\n",
    "We will enforce that constraint manually, in the \"training\" loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Loss Function\n",
    "PULSE searches for a latent vector $z$ that minimizes:\n",
    "$$ | DS(G(z)) - I_{LR} |_p^p $$\n",
    "\n",
    "where $I_{LR}$ is given low-resolution image (`img_lr` in the code), $G$ is a `generator` and $DS$ stands for a downsampling function.\n",
    "We will set $p=2$, that is, we will minimize _mean square error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample function\n",
    "As in the paper, we choose bicubic interpolation to downsample generated super-resolution image.\n",
    "If you wish to learn more about the bicubic interpolation, check out awesome [video by Computerphile](https://www.youtube.com/watch?v=poY_nGzEEWM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds(img_sr, target_res):\n",
    "    \"\"\"Downsamples `img` bicubically to `target_res` resolution\"\"\"\n",
    "    return nn.functional.interpolate(img_sr, target_res, mode='bicubic', align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready to run the PULSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PULSE\n",
    "At every step of PULSE, we will:\n",
    " 1. Tile the latent vector $z$ 18 times\n",
    " 2. Fit the $z$ to the mapping gaussian\n",
    " 3. Generate supe-resolution image `img_sr`\n",
    "     * StyleGAN outputs values in $[-1, 1]$, we should normalize it back to $[0, 1]$\n",
    " 4. Downsample `img_sr` image to match the resolution of given low-resolution image `img_lr`\n",
    " 4. Compute MSE loss between given `img_lr` and downsampled `img_sr`\n",
    " 5. Save some intermediate results for further analysis\n",
    " 6. Optimize $z$\n",
    " 7. Project $z$ back to the hypersphere, that is:\n",
    "     * first project it to the unit sphere (i.e. divide $z$ by its length)\n",
    "     * then multiply $z$ by radius $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_imgs = []\n",
    "min_mse = float(\"inf\")\n",
    "steps = 100\n",
    "\n",
    "for step in range(steps):\n",
    "   \n",
    "    optim.zero_grad()\n",
    "\n",
    "    #  1. Tile the latent vector\n",
    "    z = latent.expand(-1, 18, -1)\n",
    "    \n",
    "    #  2. Fit z to gaussian\n",
    "    z = lrelu(z * gaussian_fit[\"std\"] + gaussian_fit[\"mean\"])\n",
    "\n",
    "    #  3. Generate super-resolution image\n",
    "    img_sr = generator(z, noise)\n",
    "    img_sr = (img_sr + 1.0) / 2.0\n",
    "    \n",
    "    #  4. Downsample generated image\n",
    "    img_sr_ds = ds(img_sr, img_lr_res)\n",
    "        \n",
    "    #  5. Get the loss\n",
    "    loss = mse(img_lr, img_sr_ds)\n",
    "    \n",
    "    #  6. Save some images\n",
    "    if loss < min_mse:\n",
    "        best_imgs.append(img_sr.detach().clone())\n",
    "        min_mse = loss.detach()\n",
    "        \n",
    "    #  7. Optimize \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    #  8. Project z back to the hypersphere\n",
    "    with torch.no_grad():\n",
    "        latent.div_(latent.norm(dim=2, keepdim=True) + 1e-10)\n",
    "        latent.mul_(radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note might not necessarily get a satisfactory image.\n",
    "We consider generated image _satisfactory_ if the loss is less than 0.002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss: {:.4}. \".format(loss), end='')\n",
    "if loss >= 0.002:\n",
    "    print(\"Generated image might not be satisfactory. Try running the PULSE loop again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results\n",
    "Let's have some fun with the results.\n",
    "Let's plot original image, generated one, and its downsampled version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(img):\n",
    "    \"\"\"Converts a tensor image to numpy array.\"\"\"\n",
    "    return np.array(transforms.ToPILImage()(img.cpu()))\n",
    "\n",
    "before = to_numpy(img_lr[0])\n",
    "after = to_numpy(img_sr[0])\n",
    "after_lr = to_numpy(img_sr_ds[0])\n",
    "\n",
    "titles = ['Low-resolution (given)', 'Super-resolution (generated)', 'Super-resolution downsampled']\n",
    "imgs = [before, after, after_lr]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 12))\n",
    "\n",
    "for a, img, title in zip(axs, imgs, titles):\n",
    "    a.imshow(img)\n",
    "    a.axis('off')\n",
    "    a.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show intermediate pics\n",
    "Also, let's visulize the generative process by displaying intermediately generated images.\n",
    "We will get at most 16, evenly spaced images among all `best_generated` images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg = len(best_imgs)\n",
    "\n",
    "num_samples = 16 if nimg >= 16 else nimg\n",
    "idx = np.linspace(0, nimg-1, num=num_samples, endpoint=True, dtype=int)\n",
    "\n",
    "disp_imgs = np.array(best_imgs)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(disp_imgs), figsize=(6*len(disp_imgs), 6))\n",
    "\n",
    "for a, img in zip(axs, disp_imgs):\n",
    "    a.imshow(to_numpy(img[0]))\n",
    "    a.axis('off')\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genereate a gif\n",
    "In addition to the above, we may generate animated gif. The result saves to `out.gif`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = [transforms.ToPILImage()(img[0].cpu()).resize((256, 256)) for img in disp_imgs]\n",
    "\n",
    "gif[0].save('img/out.gif', save_all=True, append_images=gif[1:], loop=0, duration=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Animated face.gif](img/out.gif \"animated face\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading\n",
    "If you wish to learn more, check out the original paper:\n",
    " - in [CVPR 2020 proceedings](https://openaccess.thecvf.com/content_CVPR_2020/papers/Menon_PULSE_Self-Supervised_Photo_Upsampling_via_Latent_Space_Exploration_of_Generative_CVPR_2020_paper.pdf)\n",
    " - or its [arxiv vesion](https://arxiv.org/abs/2003.03808) – this one includes a comprehensive appendix\n",
    "\n",
    "Also, give my medium.com article a try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above notebook I have used:\n",
    " - `stylegan.py` - StyleGAN code by [@lernapparat](https://github.com/lernapparat/lernapparat/blob/master/style_gan/pytorch_style_gan.ipynb), later adapted by the paper authors\n",
    " - pretrained StyleGAN's Synthesis module (`models/synthesis.pt`) and gaussain fit data (`models/gaussian_fit.pt`) provided by the paper authors\n",
    " \n",
    "I have written this notebook as well as medium.com article as a part of academic project at The University of Tokyo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "お疲れ様！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
